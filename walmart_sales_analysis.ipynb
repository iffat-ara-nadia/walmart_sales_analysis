{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "563ac824-4661-4558-8de3-92d1dd0a0314",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import libraries\n",
    "# !pip install kaggle # # Now we can call an api to download the dataset\n",
    "import kaggle\n",
    "import pandas as pd\n",
    "import zipfile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3738168-9372-463c-a5fb-7a44d4126de9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Working with MySql Database\n",
    "!pip install mysql-connector-python\n",
    "\n",
    "# Alternatively: !pip install pymysql\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed2800a2-c20f-4ae5-b70f-47ceec281484",
   "metadata": {},
   "outputs": [],
   "source": [
    "# download dataset using kaggle api\n",
    "!kaggle datasets download najir0123/walmart-10k-sales-datasets -f Walmart.csv\n",
    "# kaggle: error: argument command: invalid choice: 'dataset' "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "715f8d98-4855-4df1-b543-791c70fc3d32",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(pd.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bbeb1fd4-363e-46d3-bf13-c85484719a2d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10051, 11)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"Walmart.csv\", encoding_errors='ignore') # to ignore any issue/ inconsistency in the dataset.\n",
    "df\n",
    "df.shape # shape gives us total number of rows and columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "636f914e-b0fe-4124-9a08-1263e3960d07",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5de9db71-c194-4131-a898-0a79aef3ae37",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>invoice_id</th>\n",
       "      <th>quantity</th>\n",
       "      <th>rating</th>\n",
       "      <th>profit_margin</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>10051.000000</td>\n",
       "      <td>10020.000000</td>\n",
       "      <td>10051.000000</td>\n",
       "      <td>10051.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>5025.741220</td>\n",
       "      <td>2.353493</td>\n",
       "      <td>5.825659</td>\n",
       "      <td>0.393791</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>2901.174372</td>\n",
       "      <td>1.602658</td>\n",
       "      <td>1.763991</td>\n",
       "      <td>0.090669</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>0.180000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>2513.500000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>0.330000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>5026.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>0.330000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>7538.500000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>0.480000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>10000.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>0.570000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         invoice_id      quantity        rating  profit_margin\n",
       "count  10051.000000  10020.000000  10051.000000   10051.000000\n",
       "mean    5025.741220      2.353493      5.825659       0.393791\n",
       "std     2901.174372      1.602658      1.763991       0.090669\n",
       "min        1.000000      1.000000      3.000000       0.180000\n",
       "25%     2513.500000      1.000000      4.000000       0.330000\n",
       "50%     5026.000000      2.000000      6.000000       0.330000\n",
       "75%     7538.500000      3.000000      7.000000       0.480000\n",
       "max    10000.000000     10.000000     10.000000       0.570000"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# To get some Statistics about dataset: describe() \n",
    "df.describe() # wrong describe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9701038e-4501-43ae-863c-583da44df639",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "53fe0197-3c8f-4816-b1ea-b1e77398e8d6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "51"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Find all duplicates\n",
    "df.duplicated().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8ebac52e-618a-4b21-9a90-3654272ac7d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove all duplicates\n",
    "df.drop_duplicates(inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0cb1246a-14ad-46ea-ba1a-64b7372c3e05",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.duplicated().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2358bb97-9fdf-4548-8bc2-6c081effb327",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 11)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# After removing duplicates the Shape of the data is also reduced\n",
    "df.shape # now it's (10000, 11), earlier it was (10051, 11)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6f4d9c21-870b-4401-867e-69a5aa5af664",
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove null values\n",
    "df.isnull().sum() # unit_price = 31, quantity = 31 null values\n",
    "\n",
    "# we need to deal with this null values. \n",
    "# there are 2 ways to deal with it\n",
    "# one wayis replace null values with some other values, the other way is remove all Rows with 31 null values.\n",
    "# In this case, we are going to drop these null values, not replacing it.\n",
    "\n",
    "# DROPPING all rows with missing records/values\n",
    "df.dropna(inplace = True) # inplace = True means it will drop the values completely from the Dataframe\n",
    "# AttributeError: 'DataFrame' object has no attribute 'drop_na'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "84924142-aac0-4c31-a0dc-bb30fb0337fa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "invoice_id        0\n",
       "Branch            0\n",
       "City              0\n",
       "category          0\n",
       "unit_price        0\n",
       "quantity          0\n",
       "date              0\n",
       "time              0\n",
       "payment_method    0\n",
       "rating            0\n",
       "profit_margin     0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Verify if there is null value after dropping all null values\n",
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1aa43613-97b8-4cce-9f37-b30376fb621e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(9969, 11)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape # now total records has also reduced"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4025e929-8a87-486e-8a5e-f2b30540991f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "invoice_id          int64\n",
       "Branch             object\n",
       "City               object\n",
       "category           object\n",
       "unit_price         object\n",
       "quantity          float64\n",
       "date               object\n",
       "time               object\n",
       "payment_method     object\n",
       "rating            float64\n",
       "profit_margin     float64\n",
       "dtype: object"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# verifing data types \n",
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f5f8bf28-3cd5-4c13-80f6-c053b5bd4289",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "could not convert string to float: '$74.69'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_13084\\3592713986.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;31m# The way we can convert data type of any column\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m \u001b[0mdf\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'unit_price'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfloat\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m# ValueError: could not convert string to float: '$74.69'\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;31m# We're getting this valueError because of $ sign infront the values.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\generic.py\u001b[0m in \u001b[0;36mastype\u001b[1;34m(self, dtype, copy, errors)\u001b[0m\n\u001b[0;32m   5910\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   5911\u001b[0m             \u001b[1;31m# else, only a single dtype is given\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 5912\u001b[1;33m             \u001b[0mnew_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_mgr\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcopy\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0merrors\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   5913\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_constructor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnew_data\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__finalize__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"astype\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   5914\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\internals\\managers.py\u001b[0m in \u001b[0;36mastype\u001b[1;34m(self, dtype, copy, errors)\u001b[0m\n\u001b[0;32m    417\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    418\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mastype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mT\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mbool\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mstr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"raise\"\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m->\u001b[0m \u001b[0mT\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 419\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"astype\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcopy\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0merrors\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    420\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    421\u001b[0m     def convert(\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\internals\\managers.py\u001b[0m in \u001b[0;36mapply\u001b[1;34m(self, f, align_keys, ignore_failures, **kwargs)\u001b[0m\n\u001b[0;32m    302\u001b[0m                     \u001b[0mapplied\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mb\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    303\u001b[0m                 \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 304\u001b[1;33m                     \u001b[0mapplied\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mb\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    305\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mTypeError\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mNotImplementedError\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    306\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mignore_failures\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\internals\\blocks.py\u001b[0m in \u001b[0;36mastype\u001b[1;34m(self, dtype, copy, errors)\u001b[0m\n\u001b[0;32m    578\u001b[0m         \u001b[0mvalues\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    579\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 580\u001b[1;33m         \u001b[0mnew_values\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mastype_array_safe\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcopy\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0merrors\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    581\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    582\u001b[0m         \u001b[0mnew_values\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmaybe_coerce_values\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnew_values\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\dtypes\\cast.py\u001b[0m in \u001b[0;36mastype_array_safe\u001b[1;34m(values, dtype, copy, errors)\u001b[0m\n\u001b[0;32m   1290\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1291\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1292\u001b[1;33m         \u001b[0mnew_values\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mastype_array\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcopy\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1293\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mValueError\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1294\u001b[0m         \u001b[1;31m# e.g. astype_nansafe can fail on object-dtype of strings\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\dtypes\\cast.py\u001b[0m in \u001b[0;36mastype_array\u001b[1;34m(values, dtype, copy)\u001b[0m\n\u001b[0;32m   1235\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1236\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1237\u001b[1;33m         \u001b[0mvalues\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mastype_nansafe\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcopy\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1238\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1239\u001b[0m     \u001b[1;31m# in pandas we don't store numpy str dtypes, so convert to object\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\dtypes\\cast.py\u001b[0m in \u001b[0;36mastype_nansafe\u001b[1;34m(arr, dtype, copy, skipna)\u001b[0m\n\u001b[0;32m   1179\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mcopy\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mis_object_dtype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marr\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mis_object_dtype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1180\u001b[0m         \u001b[1;31m# Explicit copy, or required since NumPy can't view from / to object.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1181\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0marr\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1182\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1183\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0marr\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcopy\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: could not convert string to float: '$74.69'"
     ]
    }
   ],
   "source": [
    "# WRONG syntax: df.df['unit_price'].astype[float] # AttributeError: 'DataFrame' object has no attribute 'df'\n",
    "\n",
    "# The way we can convert data type of any column\n",
    "df['unit_price'].astype(float) # ValueError: could not convert string to float: '$74.69'\n",
    "\n",
    "# We're getting this valueError because of $ sign infront the values.\n",
    "# We need to replace this $ sign or Simply remove this sign here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b26c035e-e19c-491d-b78f-e9f5af3f8b01",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Administrator\\AppData\\Local\\Temp\\ipykernel_13084\\944608874.py:3: FutureWarning: The default value of regex will change from True to False in a future version. In addition, single character regular expressions will *not* be treated as literal strings when regex=True.\n",
      "  df['unit_price'] = df['unit_price'].str.replace(\"$\", \"\")\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "invoice_id          int64\n",
       "Branch             object\n",
       "City               object\n",
       "category           object\n",
       "unit_price         object\n",
       "quantity          float64\n",
       "date               object\n",
       "time               object\n",
       "payment_method     object\n",
       "rating            float64\n",
       "profit_margin     float64\n",
       "dtype: object"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Replace $ \n",
    "\n",
    "df['unit_price'] = df['unit_price'].str.replace(\"$\", \"\")\n",
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "7cc6e6df-2db1-4d69-9093-5e211a2bd759",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>invoice_id</th>\n",
       "      <th>Branch</th>\n",
       "      <th>City</th>\n",
       "      <th>category</th>\n",
       "      <th>unit_price</th>\n",
       "      <th>quantity</th>\n",
       "      <th>date</th>\n",
       "      <th>time</th>\n",
       "      <th>payment_method</th>\n",
       "      <th>rating</th>\n",
       "      <th>profit_margin</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>WALM003</td>\n",
       "      <td>San Antonio</td>\n",
       "      <td>Health and beauty</td>\n",
       "      <td>74.69</td>\n",
       "      <td>7.0</td>\n",
       "      <td>05/01/19</td>\n",
       "      <td>13:08:00</td>\n",
       "      <td>Ewallet</td>\n",
       "      <td>9.1</td>\n",
       "      <td>0.48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>WALM048</td>\n",
       "      <td>Harlingen</td>\n",
       "      <td>Electronic accessories</td>\n",
       "      <td>15.28</td>\n",
       "      <td>5.0</td>\n",
       "      <td>08/03/19</td>\n",
       "      <td>10:29:00</td>\n",
       "      <td>Cash</td>\n",
       "      <td>9.6</td>\n",
       "      <td>0.48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>WALM067</td>\n",
       "      <td>Haltom City</td>\n",
       "      <td>Home and lifestyle</td>\n",
       "      <td>46.33</td>\n",
       "      <td>7.0</td>\n",
       "      <td>03/03/19</td>\n",
       "      <td>13:23:00</td>\n",
       "      <td>Credit card</td>\n",
       "      <td>7.4</td>\n",
       "      <td>0.33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>WALM064</td>\n",
       "      <td>Bedford</td>\n",
       "      <td>Health and beauty</td>\n",
       "      <td>58.22</td>\n",
       "      <td>8.0</td>\n",
       "      <td>27/01/19</td>\n",
       "      <td>20:33:00</td>\n",
       "      <td>Ewallet</td>\n",
       "      <td>8.4</td>\n",
       "      <td>0.33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>WALM013</td>\n",
       "      <td>Irving</td>\n",
       "      <td>Sports and travel</td>\n",
       "      <td>86.31</td>\n",
       "      <td>7.0</td>\n",
       "      <td>08/02/19</td>\n",
       "      <td>10:37:00</td>\n",
       "      <td>Ewallet</td>\n",
       "      <td>5.3</td>\n",
       "      <td>0.48</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   invoice_id   Branch         City                category  unit_price  \\\n",
       "0           1  WALM003  San Antonio       Health and beauty       74.69   \n",
       "1           2  WALM048    Harlingen  Electronic accessories       15.28   \n",
       "2           3  WALM067  Haltom City      Home and lifestyle       46.33   \n",
       "3           4  WALM064      Bedford       Health and beauty       58.22   \n",
       "4           5  WALM013       Irving       Sports and travel       86.31   \n",
       "\n",
       "   quantity      date      time payment_method  rating  profit_margin  \n",
       "0       7.0  05/01/19  13:08:00        Ewallet     9.1           0.48  \n",
       "1       5.0  08/03/19  10:29:00           Cash     9.6           0.48  \n",
       "2       7.0  03/03/19  13:23:00    Credit card     7.4           0.33  \n",
       "3       8.0  27/01/19  20:33:00        Ewallet     8.4           0.33  \n",
       "4       7.0  08/02/19  10:37:00        Ewallet     5.3           0.48  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# change data type\n",
    "df['unit_price'] = df['unit_price'].astype(float)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "715b545e-4035-4e00-84c6-022b2e573088",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verify type\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "9ee1c80d-7354-496e-bfe4-ac7c4ebd2185",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>invoice_id</th>\n",
       "      <th>Branch</th>\n",
       "      <th>City</th>\n",
       "      <th>category</th>\n",
       "      <th>unit_price</th>\n",
       "      <th>quantity</th>\n",
       "      <th>date</th>\n",
       "      <th>time</th>\n",
       "      <th>payment_method</th>\n",
       "      <th>rating</th>\n",
       "      <th>profit_margin</th>\n",
       "      <th>net_price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>WALM003</td>\n",
       "      <td>San Antonio</td>\n",
       "      <td>Health and beauty</td>\n",
       "      <td>74.69</td>\n",
       "      <td>7.0</td>\n",
       "      <td>05/01/19</td>\n",
       "      <td>13:08:00</td>\n",
       "      <td>Ewallet</td>\n",
       "      <td>9.1</td>\n",
       "      <td>0.48</td>\n",
       "      <td>522.83</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>WALM048</td>\n",
       "      <td>Harlingen</td>\n",
       "      <td>Electronic accessories</td>\n",
       "      <td>15.28</td>\n",
       "      <td>5.0</td>\n",
       "      <td>08/03/19</td>\n",
       "      <td>10:29:00</td>\n",
       "      <td>Cash</td>\n",
       "      <td>9.6</td>\n",
       "      <td>0.48</td>\n",
       "      <td>76.40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>WALM067</td>\n",
       "      <td>Haltom City</td>\n",
       "      <td>Home and lifestyle</td>\n",
       "      <td>46.33</td>\n",
       "      <td>7.0</td>\n",
       "      <td>03/03/19</td>\n",
       "      <td>13:23:00</td>\n",
       "      <td>Credit card</td>\n",
       "      <td>7.4</td>\n",
       "      <td>0.33</td>\n",
       "      <td>324.31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>WALM064</td>\n",
       "      <td>Bedford</td>\n",
       "      <td>Health and beauty</td>\n",
       "      <td>58.22</td>\n",
       "      <td>8.0</td>\n",
       "      <td>27/01/19</td>\n",
       "      <td>20:33:00</td>\n",
       "      <td>Ewallet</td>\n",
       "      <td>8.4</td>\n",
       "      <td>0.33</td>\n",
       "      <td>465.76</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>WALM013</td>\n",
       "      <td>Irving</td>\n",
       "      <td>Sports and travel</td>\n",
       "      <td>86.31</td>\n",
       "      <td>7.0</td>\n",
       "      <td>08/02/19</td>\n",
       "      <td>10:37:00</td>\n",
       "      <td>Ewallet</td>\n",
       "      <td>5.3</td>\n",
       "      <td>0.48</td>\n",
       "      <td>604.17</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   invoice_id   Branch         City                category  unit_price  \\\n",
       "0           1  WALM003  San Antonio       Health and beauty       74.69   \n",
       "1           2  WALM048    Harlingen  Electronic accessories       15.28   \n",
       "2           3  WALM067  Haltom City      Home and lifestyle       46.33   \n",
       "3           4  WALM064      Bedford       Health and beauty       58.22   \n",
       "4           5  WALM013       Irving       Sports and travel       86.31   \n",
       "\n",
       "   quantity      date      time payment_method  rating  profit_margin  \\\n",
       "0       7.0  05/01/19  13:08:00        Ewallet     9.1           0.48   \n",
       "1       5.0  08/03/19  10:29:00           Cash     9.6           0.48   \n",
       "2       7.0  03/03/19  13:23:00    Credit card     7.4           0.33   \n",
       "3       8.0  27/01/19  20:33:00        Ewallet     8.4           0.33   \n",
       "4       7.0  08/02/19  10:37:00        Ewallet     5.3           0.48   \n",
       "\n",
       "   net_price  \n",
       "0     522.83  \n",
       "1      76.40  \n",
       "2     324.31  \n",
       "3     465.76  \n",
       "4     604.17  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Derive new column 'net_price' from unit_price * quantity\n",
    "df['net_price'] = df['unit_price'] * df['quantity']\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1acef384-ef3f-43a8-a37f-7067cc42b29c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now Data Cleaning, Formatting/Processing data, Creating new columns ---everything is done.\n",
    "# So the next step will be Loading data into Database\n",
    "\n",
    "# If you're using MySQL, MAKE Sure MySql is running. Now Let's get few of the information & \n",
    "# Libraries that we're going to install\n",
    "\n",
    "# !pip install mysql-connector-python\n",
    "# pip install pymysql"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c94200d0-c0d2-4389-a96c-da4a410df3cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# CHAT GPT generated:\n",
    "\n",
    "# Set-up Connection with MySQL\n",
    "# import mysql.connector\n",
    "\n",
    "# Establish Connection\n",
    "# conn = mysql.connector.connect(\n",
    "#     host = \"localhost\",\n",
    "#     user = \"root\",\n",
    "#     password = \"costco123\",\n",
    "#     database = \"walmart\"\n",
    "# )\n",
    "\n",
    "# Create a cursor object to execute queries\n",
    "# cursor = conn.cursor()\n",
    "\n",
    "# print(\"Connected to MySQL successfully!\") # output: Connected to MySQL successfully! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "28edc5bb-9c8e-4ff3-95ae-4b6f3adbeabe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Zero Analyst Walmart SQL project Video\n",
    "# MySQL Connection:  MYSQL Toolkit \n",
    "# Using both pymysql, sqlahchemy libraries we will be able to Connect and Work with MySQL\n",
    "\n",
    "# You can also use mysql.connector\n",
    "\n",
    "import pymysql # this will work as adapter\n",
    "# Now we're going to use Pandas Data frame to export into MySQL\n",
    "from sqlalchemy import create_engine # only import this feature 'create_engine' feature which is going to make a coonection with MySQL  \n",
    "\n",
    "# For postgresSQL install and import pycopg2\n",
    "# import pycopg2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "5e2ef1e6-5e24-480e-a57b-56ba76d06d2d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pymysql in c:\\users\\administrator\\anaconda3\\lib\\site-packages (1.1.1)\n"
     ]
    }
   ],
   "source": [
    "!pip install pymysql"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "16864cdc-f918-4e39-9a42-a175325abd93",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: sqlalchemy in c:\\users\\administrator\\anaconda3\\lib\\site-packages (1.4.39)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in c:\\users\\administrator\\anaconda3\\lib\\site-packages (from sqlalchemy) (1.1.1)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install sqlalchemy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f866ac8-7fa1-48ac-b399-98cb44557a31",
   "metadata": {},
   "outputs": [],
   "source": [
    "# After installing and importing necessary Libraries, \n",
    "# now we need to set up a connection with MySQL or PostgresSQL\n",
    "\n",
    "# BLOCK COMMENT for JUPYTER NOTEBOOK: CTRL + /\n",
    "\n",
    "# mysql\n",
    "# host = localhost # localhost is the host for local machines\n",
    "# port = 3306\n",
    "# user = root\n",
    "# password = 'your_password'\n",
    "\n",
    "# PostgresSQL\n",
    "# host = localhost\n",
    "# port = 5432\n",
    "# user = postgres\n",
    "# password = 'your_password'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5865596d-8bd1-4c87-94f4-997fdaddd655",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now we're going to export data in Mysql Database\n",
    "# verify shape of the data now\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7af06d41-0a8c-42f5-935d-1e1393269e77",
   "metadata": {},
   "source": [
    "###### Issue: How to solve this problem: Dates in csv file is given as 05/01/19, but when I import this .csv file in MYSQL through python, dates are showing as 2005-01-19.\n",
    "\n",
    "###### Solution: The issue arises because MySQL interprets the date format 05/01/19 as YYYY-MM-DD, leading to incorrect date entries like 2005-01-19. To resolve this, you can preprocess the CSV file in Python to convert the dates into the YYYY-MM-DD format before importing them into MySQL. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "628bfa62-0ad2-40dd-ba4a-8ee58f140ec7",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Convert the date column from MM/DD/YY to YYYY-MM-DD\n",
    "df['date'] = pd.to_datetime(df['date']).dt.strftime('%Y-%m-%d')\n",
    "\n",
    "\n",
    "# Create csv file of cleaned data\n",
    "df.to_csv(\"walmart_clean_data.csv\", index = False)  # wrong: index = false\n",
    "# ValueError: time data '2019-01-05' does not match format '%d/%m/%y' (match)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0112549-80df-40f8-8d2b-5469efbd5251",
   "metadata": {},
   "source": [
    "###### ValueError: time data '27/01/19' does not match format '%m/%d/%y' (match)\n",
    "\n",
    "\n",
    "###### The error ValueError: time data '27/01/19' does not match format '%m/%d/%y' occurs because the date string '27/01/19' is in the format DD/MM/YY (day/month/year), whereas the format specifier '%m/%d/%y' expects MM/DD/YY (month/day/year). To resolve this issue, you need to match the format specifier to the actual format of your date strings."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4e15b70-3b27-428e-85ff-8c52ecccaee2",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "###### Important Considerations:\n",
    "\n",
    "###### Two-Digit Years: The format %y interprets two-digit years. Ensure that 05/01/19 corresponds to 2019 and not 1919. If your data includes dates from different centuries, it's safer to use four-digit years (%Y).\n",
    "\n",
    "###### Data Validation: Always validate your data after conversion to ensure accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "55bbad53-8394-4ba0-85bb-fc2f94c9ff7b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connected to MySQL successfully!\n"
     ]
    }
   ],
   "source": [
    "# Now Create a table and upload the data which is a kind of really a mess\n",
    "\n",
    "# So, we can use the Pandas Dataframe to directly export data from Dataframe to MySQL\n",
    "# within a few seconds. In this process we don't have to create a table, we don't have to do anything\n",
    "\n",
    "# Now importing any data to MySql, or postgres SQL, We will need to make a connection \n",
    "# with Python to mySQL / postgresSQL\n",
    "\n",
    "# MySQL Connection: We will use 'create_engine' to make a connection with MySQL, pOSTGRESsql BOTH\n",
    "\n",
    "# mysql + mysql adapter (pymysql): //user_name:password@localhost:port/db_name\"\n",
    "engine_mysql = create_engine(\"mysql+pymysql://root:costco123@localhost:3306/walmart\") # inside this create_engine we need to pass parameters\n",
    "\n",
    "# Error-handling\n",
    "try:\n",
    "    engine_mysql\n",
    "    print(\"Connected to MySQL successfully!\")\n",
    "except:\n",
    "    print(\"Unable to connect\")\n",
    "\n",
    "    \n",
    "# OUTPUT: Connected to MySQL successfully!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c72fad8-a6a9-4ee5-b8d3-e7329680767a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce680181-7585-483a-ab25-87899ab73f8e",
   "metadata": {},
   "outputs": [],
   "source": [
    " # help(df.to_sql)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "34122da7-73a3-4b24-870c-1f260f0ca8e8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9969"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Now we'll be using Pandas Dataframe to export data automatically to Mysql.\n",
    "\n",
    "# exporting to mysql iwth mandatory parameters\n",
    "# if_exists = append(table with no data) / replace(table with existing data) / \n",
    "df.to_sql(name=\"walmart_sales_analysis\", con=engine_mysql, if_exists='replace', index=False) #index=False means we don't want to export index\n",
    "\n",
    "# personal NOTE: All cleaning and preprocessing is done inside dataframe 'df' directly,\n",
    "# this 'df' is converted to cleaned csv file and this df data is directly uploaded to mysql, not the csv file"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0eb5b81-0646-45ab-9e52-066aa9c608f7",
   "metadata": {},
   "source": [
    "###### In the pandas.DataFrame.to_sql() method, the if_exists parameter determines the behavior when the specified table already exists in the database. The available options for if_exists are:\n",
    "\n",
    "###### 'fail': Raises a ValueError if the table already exists. This is the default behavior.\n",
    "###### 'replace': Drops the existing table and creates a new one, inserting the DataFrame's data.\n",
    "###### 'append': Inserts the data into the existing table without altering its structure. If the table does not exist, it will be created.\n",
    "###### For example, to replace an existing table with the DataFrame's data:\n",
    "\n",
    "###### df.to_sql(name='table_name', con=engine, if_exists='replace', index=False)\n",
    "###### This command will drop the existing table_name and create a new one with the contents of df.\n",
    "\n",
    "###### Important Considerations:\n",
    "\n",
    "###### Data Loss: Using if_exists='replace' will delete the existing table and its data before creating a new one. Ensure this is the desired action to prevent unintentional data loss.\n",
    "\n",
    "###### Table Schema: The new table will be created based on the DataFrame's structure, which might differ from the original table's schema.\n",
    "\n",
    "###### Indexes and Constraints: Any indexes, constraints, or triggers associated with the original table will be lost when the table is dropped. You'll need to redefine them after the new table is created if necessary."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6558693f-9cbf-48bd-994a-378af0db6d6a",
   "metadata": {},
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd6b50ad-2640-4d18-b908-4a26acf03c46",
   "metadata": {},
   "outputs": [],
   "source": [
    "# NOW Do the exploratory data analysis (EDA) for Business Analysis using SQL\n",
    "# Go to MySQl for EDA using SQL\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe0955e6-1fc6-4eaf-a039-b224b6468cad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# There is a MINOR problem FOR MySQl: in the table 'walmart_sales_analysis', there are 2 column_names (Branch, City) which are written in Capital letterS.\n",
    "# So we can change the column names all letters written in lower case and then export it back.\n",
    "\n",
    "# To do this, 1st we have to DROP the Table from MYSQL database and then try to export it back from python.\n",
    "\n",
    "# There is a minor problem with MySQL: in the table 'walmart_sales_analysis', there are two column names ('Branch' and 'City') that are written in capital letters. We can change the column names to all lowercase letters and then export the table back.\n",
    "# We just need to convert all the column names in lower case."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "7932a72a-db6c-4040-8db8-187f4222080e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['invoice_id', 'branch', 'city', 'category', 'unit_price', 'quantity',\n",
       "       'date', 'time', 'payment_method', 'rating', 'profit_margin',\n",
       "       'net_price'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# In Dataframe,using columns and str function lower() we can convert all the column names into lower case.\n",
    "df.columns = df.columns.str.lower()\n",
    "df.columns # Now every column name is converted to lower case.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "d47effec-f339-4e52-96a8-17573a915ae0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9969"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# As we've already deleted the table, we are going to export the table again.\n",
    "df.to_sql(name=\"walmart_sales_analysis\", con=engine_mysql, if_exists='replace', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73b3f2d2-5567-4cf2-b2da-19db27f892a7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
